{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f636030-633a-48b2-b1a1-208a77b569a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Encoding\\nDefinition: Data encoding is the process of transforming categorical data or text data into numerical values that can be understood and processed by machine learning algorithms. Encoding is essential because most algorithms require numerical inputs and cannot work with raw categorical data directly.\\n\\nTypes of Data Encoding:\\nLabel Encoding:\\n\\nDescription: Assigns a unique integer to each category.\\n\\nUse Case: Useful for ordinal data where the order of categories matters.\\n\\nExample: Converting [\"apple\", \"banana\", \"cherry\"] to [0, 1, 2].\\n\\nOne-Hot Encoding:\\n\\nDescription: Creates binary columns for each category, with a 1 in the column corresponding to the category and 0 elsewhere.\\n\\nUse Case: Useful for nominal data where the order does not matter.\\n\\nExample: Converting [\"apple\", \"banana\", \"cherry\"] to [[1, 0, 0], [0, 1, 0], [0, 0, 1]].\\n\\nBinary Encoding:\\n\\nDescription: Combines the advantages of both label encoding and one-hot encoding. It first converts categories to label encoding, then converts those integer labels to binary numbers.\\n\\nUse Case: Useful when dealing with high cardinality data.\\n\\nExample: Converting [\"apple\", \"banana\", \"cherry\"] might result in binary representations like [\\'000\\', \\'001\\', \\'010\\'].\\n\\nFrequency Encoding:\\n\\nDescription: Replaces the categories with the frequency of their occurrences.\\n\\nUse Case: Useful when the frequency of a category can provide useful information.\\n\\nExample: If [\"apple\", \"apple\", \"banana\", \"cherry\"] appears, then apple might be replaced by 2, banana by 1, and cherry by 1.\\n\\nTarget Encoding:\\n\\nDescription: Replaces categories with the mean of the target variable for that category.\\n\\nUse Case: Commonly used in regression and some classification problems.\\n\\nExample: If the average price of houses by neighborhood is encoded based on historical data.\\n\\nImportance in Data Science:\\nAlgorithm Compatibility:\\n\\nMost machine learning algorithms, especially those based on mathematical equations, require numerical input. Encoding transforms categorical data into numerical form, making it compatible with these algorithms.\\n\\nImproves Model Performance:\\n\\nProper encoding can help algorithms better understand the data patterns, leading to more accurate models.\\n\\nFeature Engineering:\\n\\nEncoding is a crucial step in feature engineering, allowing the creation of meaningful numerical features from categorical data.\\n\\nHandles Categorical Variables:\\n\\nMany real-world datasets contain categorical variables (e.g., gender, country, product type). Encoding enables the use of these variables in predictive modeling.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q.1\n",
    "\"\"\"Data Encoding\n",
    "Definition: Data encoding is the process of transforming categorical data or text data into numerical values that can be understood and processed by machine learning algorithms. Encoding is essential because most algorithms require numerical inputs and cannot work with raw categorical data directly.\n",
    "\n",
    "Types of Data Encoding:\n",
    "Label Encoding:\n",
    "\n",
    "Description: Assigns a unique integer to each category.\n",
    "\n",
    "Use Case: Useful for ordinal data where the order of categories matters.\n",
    "\n",
    "Example: Converting [\"apple\", \"banana\", \"cherry\"] to [0, 1, 2].\n",
    "\n",
    "One-Hot Encoding:\n",
    "\n",
    "Description: Creates binary columns for each category, with a 1 in the column corresponding to the category and 0 elsewhere.\n",
    "\n",
    "Use Case: Useful for nominal data where the order does not matter.\n",
    "\n",
    "Example: Converting [\"apple\", \"banana\", \"cherry\"] to [[1, 0, 0], [0, 1, 0], [0, 0, 1]].\n",
    "\n",
    "Binary Encoding:\n",
    "\n",
    "Description: Combines the advantages of both label encoding and one-hot encoding. It first converts categories to label encoding, then converts those integer labels to binary numbers.\n",
    "\n",
    "Use Case: Useful when dealing with high cardinality data.\n",
    "\n",
    "Example: Converting [\"apple\", \"banana\", \"cherry\"] might result in binary representations like ['000', '001', '010'].\n",
    "\n",
    "Frequency Encoding:\n",
    "\n",
    "Description: Replaces the categories with the frequency of their occurrences.\n",
    "\n",
    "Use Case: Useful when the frequency of a category can provide useful information.\n",
    "\n",
    "Example: If [\"apple\", \"apple\", \"banana\", \"cherry\"] appears, then apple might be replaced by 2, banana by 1, and cherry by 1.\n",
    "\n",
    "Target Encoding:\n",
    "\n",
    "Description: Replaces categories with the mean of the target variable for that category.\n",
    "\n",
    "Use Case: Commonly used in regression and some classification problems.\n",
    "\n",
    "Example: If the average price of houses by neighborhood is encoded based on historical data.\n",
    "\n",
    "Importance in Data Science:\n",
    "Algorithm Compatibility:\n",
    "\n",
    "Most machine learning algorithms, especially those based on mathematical equations, require numerical input. Encoding transforms categorical data into numerical form, making it compatible with these algorithms.\n",
    "\n",
    "Improves Model Performance:\n",
    "\n",
    "Proper encoding can help algorithms better understand the data patterns, leading to more accurate models.\n",
    "\n",
    "Feature Engineering:\n",
    "\n",
    "Encoding is a crucial step in feature engineering, allowing the creation of meaningful numerical features from categorical data.\n",
    "\n",
    "Handles Categorical Variables:\n",
    "\n",
    "Many real-world datasets contain categorical variables (e.g., gender, country, product type). Encoding enables the use of these variables in predictive modeling.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87dbce24-e92f-41ad-af30-a5be01630b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nominal Encoding\\nDefinition: Nominal encoding, also known as categorical encoding, is a method used to convert categorical variables with no inherent order or ranking into numerical values that can be utilized by machine learning algorithms. Unlike ordinal encoding, where the order of categories matters, nominal encoding treats categories as distinct entities without any sequence.\\n\\nTypes of Nominal Encoding\\nOne-Hot Encoding:\\n\\nDescription: Creates binary (0 or 1) columns for each category. Each original category value gets its own column, and a 1 indicates the presence of that category.\\n\\nUse Case: Preferred when the categorical variable has a small number of categories.\\n\\nLabel Encoding:\\n\\nDescription: Assigns a unique integer to each category. While simple, it can inadvertently introduce ordinal relationships that don\\'t exist.\\n\\nUse Case: Suitable for tree-based models that can handle categorical variables.\\n\\nBinary Encoding:\\n\\nDescription: Combines label encoding and binary encoding. Each category is first converted into a numerical value, then further converted into a binary code.\\n\\nUse Case: Effective for high cardinality features.\\n\\nFrequency Encoding:\\n\\nDescription: Replaces categories with their respective frequencies in the dataset.\\n\\nUse Case: Useful when the frequency of occurrence is relevant to the prediction.\\n\\nReal-World Scenario Example: One-Hot Encoding for a Food Delivery Service\\nImagine you are building a recommendation system for a food delivery service. The dataset includes a categorical feature cuisine_type with categories such as \"Italian\", \"Chinese\", \"Indian\", and \"Mexican\". To make this feature usable for a machine learning model, you could use one-hot encoding.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q.2\n",
    "\"\"\"Nominal Encoding\n",
    "Definition: Nominal encoding, also known as categorical encoding, is a method used to convert categorical variables with no inherent order or ranking into numerical values that can be utilized by machine learning algorithms. Unlike ordinal encoding, where the order of categories matters, nominal encoding treats categories as distinct entities without any sequence.\n",
    "\n",
    "Types of Nominal Encoding\n",
    "One-Hot Encoding:\n",
    "\n",
    "Description: Creates binary (0 or 1) columns for each category. Each original category value gets its own column, and a 1 indicates the presence of that category.\n",
    "\n",
    "Use Case: Preferred when the categorical variable has a small number of categories.\n",
    "\n",
    "Label Encoding:\n",
    "\n",
    "Description: Assigns a unique integer to each category. While simple, it can inadvertently introduce ordinal relationships that don't exist.\n",
    "\n",
    "Use Case: Suitable for tree-based models that can handle categorical variables.\n",
    "\n",
    "Binary Encoding:\n",
    "\n",
    "Description: Combines label encoding and binary encoding. Each category is first converted into a numerical value, then further converted into a binary code.\n",
    "\n",
    "Use Case: Effective for high cardinality features.\n",
    "\n",
    "Frequency Encoding:\n",
    "\n",
    "Description: Replaces categories with their respective frequencies in the dataset.\n",
    "\n",
    "Use Case: Useful when the frequency of occurrence is relevant to the prediction.\n",
    "\n",
    "Real-World Scenario Example: One-Hot Encoding for a Food Delivery Service\n",
    "Imagine you are building a recommendation system for a food delivery service. The dataset includes a categorical feature cuisine_type with categories such as \"Italian\", \"Chinese\", \"Indian\", and \"Mexican\". To make this feature usable for a machine learning model, you could use one-hot encoding.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5c018a-247d-4bb5-bbdb-cd8071c90b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nominal Encoding vs. One-Hot Encoding\\nWhile one-hot encoding is a popular method for handling categorical data, there are certain scenarios where nominal encoding methods, such as label encoding, frequency encoding, or binary encoding, are preferred.\\n\\nSituations Where Nominal Encoding is Preferred:\\nHigh Cardinality:\\n\\nScenario: When the categorical variable has a large number of unique categories, one-hot encoding can create a very sparse matrix with a high number of dimensions, which can be computationally expensive and less efficient.\\n\\nNominal Encoding: Label encoding or binary encoding can significantly reduce the number of features, making the dataset more manageable.\\n\\nTree-Based Models:\\n\\nScenario: Algorithms like decision trees or random forests can handle categorical data more efficiently when encoded as integers. These models can inherently manage the relationships between categories without the need for binary representation.\\n\\nNominal Encoding: Label encoding is often sufficient for tree-based models, allowing them to split on categorical variables directly.\\n\\nOrdinal Categories:\\n\\nScenario: When the categorical variable has an inherent order (e.g., education level: high school, bachelor's, master's, PhD), preserving this order is important.\\n\\nNominal Encoding: Label encoding can maintain the ordinal relationships, which might be lost in one-hot encoding.\\n\\nFrequency-Based Relationships:\\n\\nScenario: When the frequency of a category is indicative of its importance (e.g., categories with higher frequencies might have different impacts on the target variable).\\n\\nNominal Encoding: Frequency encoding can capture this relationship, whereas one-hot encoding treats all categories equally.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q.3\n",
    "\"\"\"Nominal Encoding vs. One-Hot Encoding\n",
    "While one-hot encoding is a popular method for handling categorical data, there are certain scenarios where nominal encoding methods, such as label encoding, frequency encoding, or binary encoding, are preferred.\n",
    "\n",
    "Situations Where Nominal Encoding is Preferred:\n",
    "High Cardinality:\n",
    "\n",
    "Scenario: When the categorical variable has a large number of unique categories, one-hot encoding can create a very sparse matrix with a high number of dimensions, which can be computationally expensive and less efficient.\n",
    "\n",
    "Nominal Encoding: Label encoding or binary encoding can significantly reduce the number of features, making the dataset more manageable.\n",
    "\n",
    "Tree-Based Models:\n",
    "\n",
    "Scenario: Algorithms like decision trees or random forests can handle categorical data more efficiently when encoded as integers. These models can inherently manage the relationships between categories without the need for binary representation.\n",
    "\n",
    "Nominal Encoding: Label encoding is often sufficient for tree-based models, allowing them to split on categorical variables directly.\n",
    "\n",
    "Ordinal Categories:\n",
    "\n",
    "Scenario: When the categorical variable has an inherent order (e.g., education level: high school, bachelor's, master's, PhD), preserving this order is important.\n",
    "\n",
    "Nominal Encoding: Label encoding can maintain the ordinal relationships, which might be lost in one-hot encoding.\n",
    "\n",
    "Frequency-Based Relationships:\n",
    "\n",
    "Scenario: When the frequency of a category is indicative of its importance (e.g., categories with higher frequencies might have different impacts on the target variable).\n",
    "\n",
    "Nominal Encoding: Frequency encoding can capture this relationship, whereas one-hot encoding treats all categories equally.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f44c6cc-c448-475b-89df-f874e875e331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One-Hot Encoding:\\nHow It Works:\\n\\nOne-Hot Encoding transforms categorical data into a binary matrix. For each unique category, it creates a binary column, and each record has a 1 in the column corresponding to its category and 0 in others.\\nReasons for Choosing One-Hot Encoding:\\nSmall Number of Categories: With only 5 unique values, One-Hot Encoding efficiently transforms the data without creating a large and sparse matrix. This approach remains manageable and computationally feasible.\\n\\nNo Implicit Order: One-Hot Encoding does not assume any order among the categories, which is perfect for nominal data where no such order exists.\\n\\nAlgorithm Compatibility: Many machine learning algorithms, such as linear regression, logistic regression, and neural networks, require numerical input and benefit from the binary nature of One-Hot Encoded data.\\n\\nInterpretability: Each category gets its own column, making it clear and easy to interpret which category each value belongs to.\\n\\nConclusion:\\nOne-Hot Encoding is ideal for datasets with a small number of unique categories. It converts categorical values into a format that is easily interpretable and compatible with many machine learning algorithms, ensuring that your model can effectively utilize the encoded features.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.4\n",
    "\"\"\"One-Hot Encoding:\n",
    "How It Works:\n",
    "\n",
    "One-Hot Encoding transforms categorical data into a binary matrix. For each unique category, it creates a binary column, and each record has a 1 in the column corresponding to its category and 0 in others.\n",
    "Reasons for Choosing One-Hot Encoding:\n",
    "Small Number of Categories: With only 5 unique values, One-Hot Encoding efficiently transforms the data without creating a large and sparse matrix. This approach remains manageable and computationally feasible.\n",
    "\n",
    "No Implicit Order: One-Hot Encoding does not assume any order among the categories, which is perfect for nominal data where no such order exists.\n",
    "\n",
    "Algorithm Compatibility: Many machine learning algorithms, such as linear regression, logistic regression, and neural networks, require numerical input and benefit from the binary nature of One-Hot Encoded data.\n",
    "\n",
    "Interpretability: Each category gets its own column, making it clear and easy to interpret which category each value belongs to.\n",
    "\n",
    "Conclusion:\n",
    "One-Hot Encoding is ideal for datasets with a small number of unique categories. It converts categorical values into a format that is easily interpretable and compatible with many machine learning algorithms, ensuring that your model can effectively utilize the encoded features.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179d2a15-a172-4ef6-87ee-9d3fade4ae6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCategorical columns: 2\\n\\nNumerical columns: 3\\n\\nDetermine Unique Categories in Each Categorical Column:\\n\\nLet’s assume the first categorical column has \\n𝑘\\n1\\n unique categories.\\n\\nLet’s assume the second categorical column has \\n𝑘\\n2\\n unique categories.\\n\\nApplying One-Hot Encoding:\\n\\nOne-Hot Encoding converts each unique category in a categorical column to a separate binary column.\\n\\nFor a categorical column with \\n𝑘\\n unique categories, One-Hot Encoding creates \\n𝑘\\n new binary columns.\\n\\nCalculate Total New Columns:\\n\\nFirst Categorical Column: \\n𝑘\\n1\\n new columns\\n\\nSecond Categorical Column: \\n𝑘\\n2\\n new columns\\n\\nTotal New Columns Created: \\n𝑘\\n1\\n+\\n𝑘\\n2\\n\\nExample Calculation:\\nLet’s assume:\\n\\nThe first categorical column has 4 unique categories (\\n𝑘\\n1\\n=\\n4\\n)\\n\\nThe second categorical column has 3 unique categories (\\n𝑘\\n2\\n=\\n3\\n)\\n\\nUsing One-Hot Encoding:\\n\\nFirst Categorical Column: Creates 4 new columns\\n\\nSecond Categorical Column: Creates 3 new columns\\n\\nTotal Columns Calculation:\\nNew\\xa0columns\\n=\\n4\\n+\\n3\\n=\\n7\\nOverall Dataset:\\nOriginal Columns: 5 (including the two categorical and three numerical columns)\\n\\nTransformed Columns: 3 (numerical) + 7 (new categorical) = 10\\n\\nResult:\\nNew Columns Created: 7\\n\\nTotal Columns after Transformation: 10\\n\\nSummary:\\nAfter applying One-Hot Encoding to the categorical columns, the dataset would have 7 additional columns. The total number of columns in the transformed dataset would be 10.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.5\n",
    "\"\"\"\n",
    "Categorical columns: 2\n",
    "\n",
    "Numerical columns: 3\n",
    "\n",
    "Determine Unique Categories in Each Categorical Column:\n",
    "\n",
    "Let’s assume the first categorical column has \n",
    "𝑘\n",
    "1\n",
    " unique categories.\n",
    "\n",
    "Let’s assume the second categorical column has \n",
    "𝑘\n",
    "2\n",
    " unique categories.\n",
    "\n",
    "Applying One-Hot Encoding:\n",
    "\n",
    "One-Hot Encoding converts each unique category in a categorical column to a separate binary column.\n",
    "\n",
    "For a categorical column with \n",
    "𝑘\n",
    " unique categories, One-Hot Encoding creates \n",
    "𝑘\n",
    " new binary columns.\n",
    "\n",
    "Calculate Total New Columns:\n",
    "\n",
    "First Categorical Column: \n",
    "𝑘\n",
    "1\n",
    " new columns\n",
    "\n",
    "Second Categorical Column: \n",
    "𝑘\n",
    "2\n",
    " new columns\n",
    "\n",
    "Total New Columns Created: \n",
    "𝑘\n",
    "1\n",
    "+\n",
    "𝑘\n",
    "2\n",
    "\n",
    "Example Calculation:\n",
    "Let’s assume:\n",
    "\n",
    "The first categorical column has 4 unique categories (\n",
    "𝑘\n",
    "1\n",
    "=\n",
    "4\n",
    ")\n",
    "\n",
    "The second categorical column has 3 unique categories (\n",
    "𝑘\n",
    "2\n",
    "=\n",
    "3\n",
    ")\n",
    "\n",
    "Using One-Hot Encoding:\n",
    "\n",
    "First Categorical Column: Creates 4 new columns\n",
    "\n",
    "Second Categorical Column: Creates 3 new columns\n",
    "\n",
    "Total Columns Calculation:\n",
    "New columns\n",
    "=\n",
    "4\n",
    "+\n",
    "3\n",
    "=\n",
    "7\n",
    "Overall Dataset:\n",
    "Original Columns: 5 (including the two categorical and three numerical columns)\n",
    "\n",
    "Transformed Columns: 3 (numerical) + 7 (new categorical) = 10\n",
    "\n",
    "Result:\n",
    "New Columns Created: 7\n",
    "\n",
    "Total Columns after Transformation: 10\n",
    "\n",
    "Summary:\n",
    "After applying One-Hot Encoding to the categorical columns, the dataset would have 7 additional columns. The total number of columns in the transformed dataset would be 10.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48c83a6-fa94-498b-8c80-a6649619070e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One-Hot Encoding transforms categorical data into a binary matrix. For each unique category, it creates a binary column, and each record has a 1 in the column corresponding to its category and 0 in others.\\n\\nJustification:\\nNominal Nature of Categories:\\n\\nSpecies, Habitat, and Diet: These categorical variables do not have an inherent order or ranking. One-Hot Encoding treats each category as distinct, without introducing any false ordinal relationships.\\n\\nAlgorithm Compatibility:\\n\\nMany Machine Learning Algorithms: Algorithms such as linear regression, logistic regression, neural networks, and K-nearest neighbors (KNN) benefit from the binary representation provided by One-Hot Encoding. It ensures that the distance measures and calculations used by these algorithms are meaningful.\\n\\nAvoiding Implicit Ordering:\\n\\nNo Implicit Order: One-Hot Encoding prevents the introduction of ordinal relationships that do not exist in the data, which can occur if label encoding is used. This is crucial for nominal data where the categories are simply different, not ordered.\\n\\nInterpretability:\\n\\nEasy Interpretation: Each category gets its own column, making it clear and easy to interpret which category each value belongs to. For example, if the species column includes Lion, Tiger, and Bear, you get separate binary columns for each species.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.6\n",
    "\"\"\"One-Hot Encoding transforms categorical data into a binary matrix. For each unique category, it creates a binary column, and each record has a 1 in the column corresponding to its category and 0 in others.\n",
    "\n",
    "Justification:\n",
    "Nominal Nature of Categories:\n",
    "\n",
    "Species, Habitat, and Diet: These categorical variables do not have an inherent order or ranking. One-Hot Encoding treats each category as distinct, without introducing any false ordinal relationships.\n",
    "\n",
    "Algorithm Compatibility:\n",
    "\n",
    "Many Machine Learning Algorithms: Algorithms such as linear regression, logistic regression, neural networks, and K-nearest neighbors (KNN) benefit from the binary representation provided by One-Hot Encoding. It ensures that the distance measures and calculations used by these algorithms are meaningful.\n",
    "\n",
    "Avoiding Implicit Ordering:\n",
    "\n",
    "No Implicit Order: One-Hot Encoding prevents the introduction of ordinal relationships that do not exist in the data, which can occur if label encoding is used. This is crucial for nominal data where the categories are simply different, not ordered.\n",
    "\n",
    "Interpretability:\n",
    "\n",
    "Easy Interpretation: Each category gets its own column, making it clear and easy to interpret which category each value belongs to. For example, if the species column includes Lion, Tiger, and Bear, you get separate binary columns for each species.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442bd9cd-b393-429b-b3b6-f27ae20cab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   species_Bear  species_Lion  species_Tiger  habitat_Forest  \\\n",
      "0         False          True          False           False   \n",
      "1         False         False           True            True   \n",
      "2          True         False          False            True   \n",
      "3         False          True          False           False   \n",
      "4          True         False          False            True   \n",
      "\n",
      "   habitat_Savannah  diet_Carnivore  diet_Omnivore  \n",
      "0              True            True          False  \n",
      "1             False            True          False  \n",
      "2             False           False           True  \n",
      "3              True            True          False  \n",
      "4             False           False           True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'species': ['Lion', 'Tiger', 'Bear', 'Lion', 'Bear'],\n",
    "    'habitat': ['Savannah', 'Forest', 'Forest', 'Savannah', 'Forest'],\n",
    "    'diet': ['Carnivore', 'Carnivore', 'Omnivore', 'Carnivore', 'Omnivore']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "# Apply One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['species', 'habitat', 'diet'])\n",
    "\n",
    "# Display the encoded dataframe\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f01124-08a8-45f8-8ee8-5d834257a8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To transform the categorical data in your customer churn dataset into numerical data, we will use a combination of One-Hot Encoding and Label Encoding. Here’s a step-by-step explanation of how to implement these encoding techniques:\\n\\n1. Identify Categorical and Numerical Features:\\nCategorical Features: gender, contract type\\n\\nNumerical Features: age, monthly charges, tenure\\n\\n2. Choose Encoding Techniques:\\nGender: Use Label Encoding since it has only two categories (Male and Female). This encoding is simple and efficient for binary categories.\\n\\nContract Type: Use One-Hot Encoding as it can have more than two categories (e.g., Month-to-Month, One-Year, Two-Year).'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.7\n",
    "\"\"\"To transform the categorical data in your customer churn dataset into numerical data, we will use a combination of One-Hot Encoding and Label Encoding. Here’s a step-by-step explanation of how to implement these encoding techniques:\n",
    "\n",
    "1. Identify Categorical and Numerical Features:\n",
    "Categorical Features: gender, contract type\n",
    "\n",
    "Numerical Features: age, monthly charges, tenure\n",
    "\n",
    "2. Choose Encoding Techniques:\n",
    "Gender: Use Label Encoding since it has only two categories (Male and Female). This encoding is simple and efficient for binary categories.\n",
    "\n",
    "Contract Type: Use One-Hot Encoding as it can have more than two categories (e.g., Month-to-Month, One-Year, Two-Year).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033b35c-cc82-4652-90b8-9478daba5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'gender': ['Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "    'age': [34, 29, 45, 25, 50],\n",
    "    'contract_type': ['Month-to-Month', 'One-Year', 'Two-Year', 'Month-to-Month', 'One-Year'],\n",
    "    'monthly_charges': [45.5, 60.0, 89.9, 29.9, 99.5],\n",
    "    'tenure': [5, 10, 24, 1, 30]\n",
    "}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c02c34ee-49ea-469a-b0a3-1d57c5ff629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender  age   contract_type  monthly_charges  tenure  gender_encoded\n",
      "0    Male   34  Month-to-Month             45.5       5               1\n",
      "1  Female   29        One-Year             60.0      10               0\n",
      "2  Female   45        Two-Year             89.9      24               0\n",
      "3    Male   25  Month-to-Month             29.9       1               1\n",
      "4  Female   50        One-Year             99.5      30               0\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['gender_encoded'] = label_encoder.fit_transform(df['gender'])\n",
    "\n",
    "# Display the transformed dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef24ccf-4789-440c-b661-3fba1a63963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   contract_type_Month-to-Month  contract_type_One-Year  \\\n",
      "0                           1.0                     0.0   \n",
      "1                           0.0                     1.0   \n",
      "2                           0.0                     0.0   \n",
      "3                           1.0                     0.0   \n",
      "4                           0.0                     1.0   \n",
      "\n",
      "   contract_type_Two-Year   age  monthly_charges  tenure  gender_encoded  \n",
      "0                     0.0  34.0             45.5     5.0             1.0  \n",
      "1                     0.0  29.0             60.0    10.0             0.0  \n",
      "2                     1.0  45.0             89.9    24.0             0.0  \n",
      "3                     0.0  25.0             29.9     1.0             1.0  \n",
      "4                     0.0  50.0             99.5    30.0             0.0  \n"
     ]
    }
   ],
   "source": [
    "# ColumnTransformer to apply different encoders to different columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), ['contract_type'])\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "df_encoded = preprocessor.fit_transform(df.drop(columns=['gender']))\n",
    "\n",
    "# Convert the array back to a DataFrame\n",
    "df_encoded = pd.DataFrame(df_encoded, columns=['contract_type_Month-to-Month', 'contract_type_One-Year', 'contract_type_Two-Year', 'age', 'monthly_charges', 'tenure', 'gender_encoded'])\n",
    "\n",
    "# Display the encoded dataframe\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0adf297-8e55-4489-8cbf-229c502bf917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
